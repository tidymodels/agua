% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/h2o_train.R
\name{h2o_train}
\alias{h2o_train}
\alias{h2o_train_rf}
\alias{h2o_train_xgboost}
\alias{h2o_train_glm}
\title{Model wrappers for h2o}
\usage{
h2o_train(x, y, model, ...)

h2o_train_rf(x, y, ntrees = 50, mtries = -1, min_rows = 1, ...)

h2o_train_xgboost(
  x,
  y,
  ntrees = 50,
  max_depth = 6,
  min_rows = 1,
  learn_rate = 0.3,
  sample_rate = 1,
  col_sample_rate = 1,
  min_split_improvement = 0,
  stopping_rounds = 0,
  ...
)

h2o_train_glm(x, y, lambda = NULL, alpha = NULL, ...)
}
\arguments{
\item{x}{A data frame of predictors}

\item{y}{A vector of outcomes.}

\item{model}{A character string for the model. Current selections are
\code{"randomForest"}, \code{"xgboost"}, and \code{"glm"}. Use \code{\link[h2o:h2o.xgboost.available]{h2o::h2o.xgboost.available()}}
to see if that model can be used on your OS/h2o server.}

\item{...}{Other options to pass to the h2o model functions (e.g.,
\code{\link[h2o:h2o.randomForest]{h2o::h2o.randomForest()}}).}

\item{ntrees}{Number of trees. Defaults to 50.}

\item{mtries}{Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrt{p} for
classification and p/3 for regression (where p is the # of predictors Defaults to -1.}

\item{min_rows}{Fewest allowed (weighted) observations in a leaf. Defaults to 1.}

\item{max_depth}{Maximum tree depth (0 for unlimited). Defaults to 20.}

\item{learn_rate}{(same as eta) Learning rate (from 0.0 to 1.0) Defaults to 0.3.}

\item{sample_rate}{Row sample rate per tree (from 0.0 to 1.0) Defaults to 0.632.}

\item{col_sample_rate}{(same as colsample_bylevel) Column sample rate (from 0.0 to 1.0) Defaults to 1.}

\item{min_split_improvement}{Minimum relative improvement in squared error reduction for a split to happen Defaults to 1e-05.}

\item{stopping_rounds}{Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.}

\item{lambda}{Regularization strength}

\item{alpha}{Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha
represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the
amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.}
}
\value{
An h2o model object.
}
\description{
Basic model wrappers for h2o model functions that include data conversion,
seed configuration, and so on.
}
\examples{
# start with h2o::h2o.init()

if (h2o_running()) {
  # -------------------------------------------------------------------------
  # Using the model wrappers:
  h2o_train_glm(mtcars[, -1], mtcars$mpg)

  # -------------------------------------------------------------------------
  # using parsnip:

  spec <-
    rand_forest(mtry = 3, trees = 1000) \%>\%
    set_engine("h2o") \%>\%
    set_mode("regression")

  set.seed(1)
  mod <- fit(spec, mpg ~ ., data = mtcars)
  mod

  predict(mod, head(mtcars))
}
}
